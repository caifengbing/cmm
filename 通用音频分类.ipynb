{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce170de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "import time\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "import wavio\n",
    "import librosa\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,LSTM,TimeDistributed,Bidirectional\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1eab165",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_list = ['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ad0883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537\n",
      "(1, 40, 44)\n",
      "(2, 40, 44)\n",
      "*****0*****\n",
      "1573\n",
      "(1538, 40, 44)\n",
      "(1539, 40, 44)\n",
      "*****1*****\n",
      "1567\n",
      "(3111, 40, 44)\n",
      "(3112, 40, 44)\n",
      "*****2*****\n",
      "1566\n",
      "(4678, 40, 44)\n",
      "(4679, 40, 44)\n",
      "*****3*****\n",
      "2106\n",
      "(6244, 40, 44)\n",
      "(6245, 40, 44)\n",
      "*****4*****\n",
      "2095\n",
      "(8350, 40, 44)\n",
      "(8351, 40, 44)\n",
      "*****5*****\n",
      "2086\n",
      "(10445, 40, 44)\n",
      "(10446, 40, 44)\n",
      "*****6*****\n",
      "2119\n",
      "(12531, 40, 44)\n",
      "(12532, 40, 44)\n",
      "*****7*****\n",
      "2121\n",
      "(14650, 40, 44)\n",
      "(14651, 40, 44)\n",
      "*****8*****\n",
      "1562\n",
      "(16771, 40, 44)\n",
      "(16772, 40, 44)\n",
      "*****9*****\n",
      "1600\n",
      "(18333, 40, 44)\n",
      "(18334, 40, 44)\n",
      "*****10*****\n",
      "2086\n",
      "(19933, 40, 44)\n",
      "(19934, 40, 44)\n",
      "*****11*****\n",
      "1584\n",
      "(22019, 40, 44)\n",
      "(22020, 40, 44)\n",
      "*****12*****\n",
      "2105\n",
      "(23603, 40, 44)\n",
      "(23604, 40, 44)\n",
      "*****13*****\n",
      "2123\n",
      "(25708, 40, 44)\n",
      "(25709, 40, 44)\n",
      "*****14*****\n",
      "2095\n",
      "(27831, 40, 44)\n",
      "(27832, 40, 44)\n",
      "*****15*****\n",
      "2121\n",
      "(29926, 40, 44)\n",
      "(29927, 40, 44)\n",
      "*****16*****\n",
      "2122\n",
      "(32047, 40, 44)\n",
      "(32048, 40, 44)\n",
      "*****17*****\n",
      "2108\n",
      "(34169, 40, 44)\n",
      "(34170, 40, 44)\n",
      "*****18*****\n",
      "2138\n",
      "(36277, 40, 44)\n",
      "(36278, 40, 44)\n",
      "*****19*****\n",
      "1548\n",
      "(38415, 40, 44)\n",
      "(38416, 40, 44)\n",
      "*****20*****\n",
      "2125\n",
      "(39963, 40, 44)\n",
      "(39964, 40, 44)\n",
      "*****21*****\n",
      "2131\n",
      "(42088, 40, 44)\n",
      "(42089, 40, 44)\n",
      "*****22*****\n",
      "2089\n",
      "(44219, 40, 44)\n",
      "(44220, 40, 44)\n",
      "*****23*****\n",
      "1540\n",
      "(46308, 40, 44)\n",
      "(46309, 40, 44)\n",
      "*****24*****\n",
      "2109\n",
      "(47848, 40, 44)\n",
      "(47849, 40, 44)\n",
      "*****25*****\n",
      "2103\n",
      "(49957, 40, 44)\n",
      "(49958, 40, 44)\n",
      "*****26*****\n",
      "1580\n",
      "(52060, 40, 44)\n",
      "(52061, 40, 44)\n",
      "*****27*****\n",
      "2121\n",
      "(53640, 40, 44)\n",
      "(53641, 40, 44)\n",
      "*****28*****\n",
      "2126\n",
      "(55761, 40, 44)\n",
      "(55762, 40, 44)\n",
      "*****29*****\n"
     ]
    }
   ],
   "source": [
    "features,labels = np.empty((0,40,44)),np.empty(0)\n",
    "for i in range(30):\n",
    "    filePath = \"D:\\\\下载\\\\train\\\\%s\" % filename_list[i]\n",
    "    fl = os.listdir(filePath)\n",
    "    print(len(fl))\n",
    "    for j in range(len(fl)):\n",
    "        wavpath = filePath + '\\\\' + fl[j]\n",
    "        sig,sr = librosa.load(wavpath)\n",
    "        #不够长度的信号进行补0\n",
    "        x = np.pad(sig,(0,22050-sig.shape[0]),'constant')\n",
    "        #print(x.shape)\n",
    "        #提取信号的mfcc并进行标准化\n",
    "        a = librosa.feature.mfcc(x,sr,n_mfcc=40)\n",
    "        norm_mfccs = sklearn.preprocessing.scale(a,axis=1)\n",
    "        features = np.append(features,norm_mfccs[None],axis=0)\n",
    "        labels = np.append(labels,int(i))\n",
    "        if j < 2:\n",
    "            print(features.shape)\n",
    "    print('*****%s*****'%i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b143ab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537\n",
      "(1, 28, 44)\n",
      "(2, 28, 44)\n",
      "*****0*****\n",
      "1573\n",
      "(1538, 28, 44)\n",
      "(1539, 28, 44)\n",
      "*****1*****\n",
      "1567\n",
      "(3111, 28, 44)\n",
      "(3112, 28, 44)\n",
      "*****2*****\n",
      "1566\n",
      "(4678, 28, 44)\n",
      "(4679, 28, 44)\n",
      "*****3*****\n",
      "2106\n",
      "(6244, 28, 44)\n",
      "(6245, 28, 44)\n",
      "*****4*****\n",
      "2095\n",
      "(8350, 28, 44)\n",
      "(8351, 28, 44)\n",
      "*****5*****\n",
      "2086\n",
      "(10445, 28, 44)\n",
      "(10446, 28, 44)\n",
      "*****6*****\n",
      "2119\n",
      "(12531, 28, 44)\n",
      "(12532, 28, 44)\n",
      "*****7*****\n",
      "2121\n",
      "(14650, 28, 44)\n",
      "(14651, 28, 44)\n",
      "*****8*****\n",
      "1562\n",
      "(16771, 28, 44)\n",
      "(16772, 28, 44)\n",
      "*****9*****\n",
      "1600\n",
      "(18333, 28, 44)\n",
      "(18334, 28, 44)\n",
      "*****10*****\n",
      "2086\n",
      "(19933, 28, 44)\n",
      "(19934, 28, 44)\n",
      "*****11*****\n",
      "1584\n",
      "(22019, 28, 44)\n",
      "(22020, 28, 44)\n",
      "*****12*****\n",
      "2105\n",
      "(23603, 28, 44)\n",
      "(23604, 28, 44)\n",
      "*****13*****\n",
      "2123\n",
      "(25708, 28, 44)\n",
      "(25709, 28, 44)\n",
      "*****14*****\n",
      "2095\n",
      "(27831, 28, 44)\n",
      "(27832, 28, 44)\n",
      "*****15*****\n",
      "2121\n",
      "(29926, 28, 44)\n",
      "(29927, 28, 44)\n",
      "*****16*****\n",
      "2122\n",
      "(32047, 28, 44)\n",
      "(32048, 28, 44)\n",
      "*****17*****\n",
      "2108\n",
      "(34169, 28, 44)\n",
      "(34170, 28, 44)\n",
      "*****18*****\n",
      "2138\n",
      "(36277, 28, 44)\n",
      "(36278, 28, 44)\n",
      "*****19*****\n",
      "1548\n",
      "(38415, 28, 44)\n",
      "(38416, 28, 44)\n",
      "*****20*****\n",
      "2125\n",
      "(39963, 28, 44)\n",
      "(39964, 28, 44)\n",
      "*****21*****\n",
      "2131\n",
      "(42088, 28, 44)\n",
      "(42089, 28, 44)\n",
      "*****22*****\n",
      "2089\n",
      "(44219, 28, 44)\n",
      "(44220, 28, 44)\n",
      "*****23*****\n",
      "1540\n",
      "(46308, 28, 44)\n",
      "(46309, 28, 44)\n",
      "*****24*****\n",
      "2109\n",
      "(47848, 28, 44)\n",
      "(47849, 28, 44)\n",
      "*****25*****\n",
      "2103\n",
      "(49957, 28, 44)\n",
      "(49958, 28, 44)\n",
      "*****26*****\n",
      "1580\n",
      "(52060, 28, 44)\n",
      "(52061, 28, 44)\n",
      "*****27*****\n",
      "2121\n",
      "(53640, 28, 44)\n",
      "(53641, 28, 44)\n",
      "*****28*****\n",
      "2126\n",
      "(55761, 28, 44)\n",
      "(55762, 28, 44)\n",
      "*****29*****\n"
     ]
    }
   ],
   "source": [
    "features = np.empty((0,28,44))\n",
    "for i in range(30):\n",
    "    filePath = \"D:\\\\下载\\\\train\\\\%s\" % filename_list[i]\n",
    "    fl = os.listdir(filePath)\n",
    "    print(len(fl))\n",
    "    for j in range(len(fl)):\n",
    "        wavpath = filePath + '\\\\' + fl[j]\n",
    "        x,sr = librosa.load(wavpath)\n",
    "        #不够长度的信号进行补0\n",
    "        sig = np.pad(x,(0,22050-x.shape[0]),'constant')\n",
    "        a = librosa.feature.zero_crossing_rate(sig,sr)\n",
    "        b = librosa.feature.spectral_centroid(sig,sr=sr)[0]\n",
    "        a = np.vstack((a,b))\n",
    "        b = librosa.feature.chroma_stft(sig,sr)\n",
    "        a = np.vstack((a,b))\n",
    "        b = librosa.feature.spectral_contrast(sig,sr)\n",
    "        a = np.vstack((a,b))\n",
    "        b = librosa.feature.spectral_bandwidth(sig,sr)\n",
    "        a = np.vstack((a,b))\n",
    "        b = librosa.feature.tonnetz(sig,sr)\n",
    "        a = np.vstack((a,b))\n",
    "        norm_a = sklearn.preprocessing.scale(a,axis=1)\n",
    "        #print(norm_mfccs.shape)\n",
    "        features = np.append(features,norm_a[None],axis=0)\n",
    "        if j < 2:\n",
    "            print(features.shape)\n",
    "    print('*****%s*****'%i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afbf25f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6835\n",
      "(1, 40, 44)\n",
      "(2, 40, 44)\n"
     ]
    }
   ],
   "source": [
    "#测试集\n",
    "X_test = np.empty((0,40,44))\n",
    "filePath = \"D:\\\\下载\\\\test\"\n",
    "fl = os.listdir(filePath)\n",
    "print(len(fl))\n",
    "for j in range(len(fl)):\n",
    "    wavpath = filePath + '\\\\' + fl[j]\n",
    "    sig,sr = librosa.load(wavpath)\n",
    "    #不够长度的信号进行补0\n",
    "    x = np.pad(sig,(0,22050-sig.shape[0]),'constant')\n",
    "    #print(x.shape)\n",
    "    #提取信号的mfc并进行标准化\n",
    "    mfcc = librosa.feature.mfcc(x,sr,n_mfcc=40)\n",
    "    norm_mfccs = sklearn.preprocessing.scale(mfcc,axis=1)\n",
    "    X_test = np.append(X_test,norm_mfccs[None],axis=0)\n",
    "    if j < 2:\n",
    "        print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "209a116b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6835\n",
      "(1, 28, 44)\n",
      "(2, 28, 44)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.empty((0,28,44))\n",
    "filePath = \"D:\\\\下载\\\\test\"\n",
    "fl = os.listdir(filePath)\n",
    "print(len(fl))\n",
    "for j in range(len(fl)):\n",
    "    wavpath = filePath + '\\\\' + fl[j]\n",
    "    x,sr = librosa.load(wavpath)\n",
    "    #不够长度的信号进行补0\n",
    "    sig = np.pad(x,(0,22050-x.shape[0]),'constant')\n",
    "    a = librosa.feature.zero_crossing_rate(sig,sr)\n",
    "    b = librosa.feature.spectral_centroid(sig,sr=sr)[0]\n",
    "    a = np.vstack((a,b))\n",
    "    b = librosa.feature.chroma_stft(sig,sr)\n",
    "    a = np.vstack((a,b))\n",
    "    b = librosa.feature.spectral_contrast(sig,sr)\n",
    "    a = np.vstack((a,b))\n",
    "    b = librosa.feature.spectral_bandwidth(sig,sr)\n",
    "    a = np.vstack((a,b))\n",
    "    b = librosa.feature.tonnetz(sig,sr)\n",
    "    a = np.vstack((a,b))\n",
    "    norm_a = sklearn.preprocessing.scale(a,axis=1)\n",
    "    #print(norm_mfccs.shape)\n",
    "    X_test = np.append(X_test,norm_a[None],axis=0)\n",
    "    if j < 2:\n",
    "        print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e583643c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6835, 28, 44, 1)\n",
      "\n",
      "Fold 1\n",
      "(46308, 28, 44, 1)\n",
      "(11578, 28, 44, 1)\n",
      "(46308, 30)\n",
      "(11578, 30)\n",
      "Model: \"sequential\"\n",
      "________________________________________________________________________________\n",
      " Layer (type)                       Output Shape                    Param #     \n",
      "================================================================================\n",
      " conv2d (Conv2D)                    (None, 26, 42, 32)              320         \n",
      "                                                                                \n",
      " max_pooling2d (MaxPooling2D)       (None, 13, 21, 32)              0           \n",
      "                                                                                \n",
      " dropout (Dropout)                  (None, 13, 21, 32)              0           \n",
      "                                                                                \n",
      " conv2d_1 (Conv2D)                  (None, 11, 19, 32)              9248        \n",
      "                                                                                \n",
      " max_pooling2d_1 (MaxPooling2D)     (None, 5, 9, 32)                0           \n",
      "                                                                                \n",
      " dropout_1 (Dropout)                (None, 5, 9, 32)                0           \n",
      "                                                                                \n",
      " flatten (Flatten)                  (None, 1440)                    0           \n",
      "                                                                                \n",
      " dense (Dense)                      (None, 30)                      43230       \n",
      "                                                                                \n",
      "================================================================================\n",
      "Total params: 52,798\n",
      "Trainable params: 52,798\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n",
      "Epoch 1/35\n",
      "1448/1448 [==============================] - 37s 24ms/step - loss: 3.0025 - accuracy: 0.1547 - val_loss: 2.5196 - val_accuracy: 0.2939\n",
      "Epoch 2/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 2.3954 - accuracy: 0.3134 - val_loss: 2.0872 - val_accuracy: 0.4214\n",
      "Epoch 3/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 2.1369 - accuracy: 0.3825 - val_loss: 1.9327 - val_accuracy: 0.4541\n",
      "Epoch 4/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 2.0078 - accuracy: 0.4160 - val_loss: 1.8368 - val_accuracy: 0.4812\n",
      "Epoch 5/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.9286 - accuracy: 0.4361 - val_loss: 1.7770 - val_accuracy: 0.4994\n",
      "Epoch 6/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.8612 - accuracy: 0.4551 - val_loss: 1.7262 - val_accuracy: 0.5121\n",
      "Epoch 7/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.8167 - accuracy: 0.4693 - val_loss: 1.7106 - val_accuracy: 0.5154\n",
      "Epoch 8/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.7780 - accuracy: 0.4802 - val_loss: 1.6654 - val_accuracy: 0.5231\n",
      "Epoch 9/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.7397 - accuracy: 0.4872 - val_loss: 1.6067 - val_accuracy: 0.5459\n",
      "Epoch 10/35\n",
      "1448/1448 [==============================] - 35s 25ms/step - loss: 1.7044 - accuracy: 0.4959 - val_loss: 1.6076 - val_accuracy: 0.5387\n",
      "Epoch 11/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6831 - accuracy: 0.5014 - val_loss: 1.5961 - val_accuracy: 0.5465\n",
      "Epoch 12/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6681 - accuracy: 0.5040 - val_loss: 1.5453 - val_accuracy: 0.5576\n",
      "Epoch 13/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6577 - accuracy: 0.5083 - val_loss: 1.5761 - val_accuracy: 0.5463\n",
      "Epoch 14/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6368 - accuracy: 0.5154 - val_loss: 1.5474 - val_accuracy: 0.5626\n",
      "Epoch 15/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6299 - accuracy: 0.5170 - val_loss: 1.5127 - val_accuracy: 0.5698\n",
      "Epoch 16/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6158 - accuracy: 0.5209 - val_loss: 1.5108 - val_accuracy: 0.5627\n",
      "Epoch 17/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5948 - accuracy: 0.5259 - val_loss: 1.4996 - val_accuracy: 0.5711\n",
      "Epoch 18/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5871 - accuracy: 0.5269 - val_loss: 1.4951 - val_accuracy: 0.5694\n",
      "Epoch 19/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5813 - accuracy: 0.5322 - val_loss: 1.4794 - val_accuracy: 0.5729\n",
      "Epoch 20/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5609 - accuracy: 0.5340 - val_loss: 1.4678 - val_accuracy: 0.5700\n",
      "Epoch 21/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5683 - accuracy: 0.5333 - val_loss: 1.4849 - val_accuracy: 0.5726\n",
      "Epoch 22/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5562 - accuracy: 0.5364 - val_loss: 1.4808 - val_accuracy: 0.5740\n",
      "Epoch 23/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5407 - accuracy: 0.5403 - val_loss: 1.4586 - val_accuracy: 0.5765\n",
      "Epoch 24/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5382 - accuracy: 0.5413 - val_loss: 1.4617 - val_accuracy: 0.5760\n",
      "Epoch 25/35\n",
      "1448/1448 [==============================] - 37s 25ms/step - loss: 1.5267 - accuracy: 0.5441 - val_loss: 1.4581 - val_accuracy: 0.5752\n",
      "Epoch 26/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5185 - accuracy: 0.5467 - val_loss: 1.4540 - val_accuracy: 0.5798\n",
      "Epoch 27/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5194 - accuracy: 0.5466 - val_loss: 1.4408 - val_accuracy: 0.5818\n",
      "Epoch 28/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5125 - accuracy: 0.5485 - val_loss: 1.4640 - val_accuracy: 0.5709\n",
      "Epoch 29/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.5145 - accuracy: 0.5415 - val_loss: 1.4364 - val_accuracy: 0.5829\n",
      "Epoch 30/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.5045 - accuracy: 0.5511 - val_loss: 1.4652 - val_accuracy: 0.5729\n",
      "Epoch 31/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.4945 - accuracy: 0.5517 - val_loss: 1.4343 - val_accuracy: 0.5802\n",
      "Epoch 32/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.4943 - accuracy: 0.5526 - val_loss: 1.4231 - val_accuracy: 0.5878\n",
      "Epoch 33/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.4932 - accuracy: 0.5516 - val_loss: 1.4160 - val_accuracy: 0.5834\n",
      "Epoch 34/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.4810 - accuracy: 0.5542 - val_loss: 1.4216 - val_accuracy: 0.5770\n",
      "Epoch 35/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.4843 - accuracy: 0.5540 - val_loss: 1.4244 - val_accuracy: 0.5831\n",
      "\n",
      "Fold 2\n",
      "(46309, 28, 44, 1)\n",
      "(11577, 28, 44, 1)\n",
      "(46309, 30)\n",
      "(11577, 30)\n",
      "Model: \"sequential_1\"\n",
      "________________________________________________________________________________\n",
      " Layer (type)                       Output Shape                    Param #     \n",
      "================================================================================\n",
      " conv2d_2 (Conv2D)                  (None, 26, 42, 32)              320         \n",
      "                                                                                \n",
      " max_pooling2d_2 (MaxPooling2D)     (None, 13, 21, 32)              0           \n",
      "                                                                                \n",
      " dropout_2 (Dropout)                (None, 13, 21, 32)              0           \n",
      "                                                                                \n",
      " conv2d_3 (Conv2D)                  (None, 11, 19, 32)              9248        \n",
      "                                                                                \n",
      " max_pooling2d_3 (MaxPooling2D)     (None, 5, 9, 32)                0           \n",
      "                                                                                \n",
      " dropout_3 (Dropout)                (None, 5, 9, 32)                0           \n",
      "                                                                                \n",
      " flatten_1 (Flatten)                (None, 1440)                    0           \n",
      "                                                                                \n",
      " dense_1 (Dense)                    (None, 30)                      43230       \n",
      "                                                                                \n",
      "================================================================================\n",
      "Total params: 52,798\n",
      "Trainable params: 52,798\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1448/1448 [==============================] - 36s 25ms/step - loss: 3.0154 - accuracy: 0.1494 - val_loss: 2.5486 - val_accuracy: 0.2867\n",
      "Epoch 2/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 2.4506 - accuracy: 0.2997 - val_loss: 2.1613 - val_accuracy: 0.3859\n",
      "Epoch 3/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 2.2067 - accuracy: 0.3621 - val_loss: 2.0018 - val_accuracy: 0.4387\n",
      "Epoch 4/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 2.0904 - accuracy: 0.3933 - val_loss: 1.8881 - val_accuracy: 0.4644\n",
      "Epoch 5/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 2.0083 - accuracy: 0.4170 - val_loss: 1.8240 - val_accuracy: 0.4843\n",
      "Epoch 6/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.9445 - accuracy: 0.4319 - val_loss: 1.7781 - val_accuracy: 0.5000\n",
      "Epoch 7/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.8863 - accuracy: 0.4473 - val_loss: 1.7194 - val_accuracy: 0.5175\n",
      "Epoch 8/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.8262 - accuracy: 0.4647 - val_loss: 1.6677 - val_accuracy: 0.5230\n",
      "Epoch 9/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.7910 - accuracy: 0.4719 - val_loss: 1.6382 - val_accuracy: 0.5298\n",
      "Epoch 10/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.7613 - accuracy: 0.4829 - val_loss: 1.6003 - val_accuracy: 0.5430\n",
      "Epoch 11/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.7385 - accuracy: 0.4858 - val_loss: 1.6112 - val_accuracy: 0.5371\n",
      "Epoch 12/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.7084 - accuracy: 0.4964 - val_loss: 1.5718 - val_accuracy: 0.5537\n",
      "Epoch 13/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6852 - accuracy: 0.4980 - val_loss: 1.5455 - val_accuracy: 0.5521\n",
      "Epoch 14/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6711 - accuracy: 0.5030 - val_loss: 1.5555 - val_accuracy: 0.5564\n",
      "Epoch 15/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6575 - accuracy: 0.5077 - val_loss: 1.5397 - val_accuracy: 0.5580\n",
      "Epoch 16/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.6370 - accuracy: 0.5117 - val_loss: 1.5288 - val_accuracy: 0.5541\n",
      "Epoch 17/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6257 - accuracy: 0.5162 - val_loss: 1.5211 - val_accuracy: 0.5602\n",
      "Epoch 18/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6178 - accuracy: 0.5189 - val_loss: 1.5090 - val_accuracy: 0.5626\n",
      "Epoch 19/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.6152 - accuracy: 0.5181 - val_loss: 1.4910 - val_accuracy: 0.5729\n",
      "Epoch 20/35\n",
      "1448/1448 [==============================] - 35s 25ms/step - loss: 1.5876 - accuracy: 0.5298 - val_loss: 1.5033 - val_accuracy: 0.5677\n",
      "Epoch 21/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5852 - accuracy: 0.5283 - val_loss: 1.4800 - val_accuracy: 0.5721\n",
      "Epoch 22/35\n",
      "1448/1448 [==============================] - 37s 25ms/step - loss: 1.5835 - accuracy: 0.5283 - val_loss: 1.4590 - val_accuracy: 0.5820\n",
      "Epoch 23/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5639 - accuracy: 0.5331 - val_loss: 1.4600 - val_accuracy: 0.5818\n",
      "Epoch 24/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5588 - accuracy: 0.5337 - val_loss: 1.4397 - val_accuracy: 0.5820\n",
      "Epoch 25/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5480 - accuracy: 0.5369 - val_loss: 1.4453 - val_accuracy: 0.5857\n",
      "Epoch 26/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5321 - accuracy: 0.5381 - val_loss: 1.4396 - val_accuracy: 0.5791\n",
      "Epoch 27/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5306 - accuracy: 0.5435 - val_loss: 1.4291 - val_accuracy: 0.5875\n",
      "Epoch 28/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5150 - accuracy: 0.5438 - val_loss: 1.4158 - val_accuracy: 0.5863\n",
      "Epoch 29/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.5157 - accuracy: 0.5474 - val_loss: 1.4225 - val_accuracy: 0.5875\n",
      "Epoch 30/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.5047 - accuracy: 0.5469 - val_loss: 1.4346 - val_accuracy: 0.5878\n",
      "Epoch 31/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5062 - accuracy: 0.5491 - val_loss: 1.4194 - val_accuracy: 0.5909\n",
      "Epoch 32/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.4913 - accuracy: 0.5529 - val_loss: 1.4173 - val_accuracy: 0.5915\n",
      "Epoch 33/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.4899 - accuracy: 0.5541 - val_loss: 1.4059 - val_accuracy: 0.5951\n",
      "Epoch 34/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.4891 - accuracy: 0.5532 - val_loss: 1.4036 - val_accuracy: 0.5921\n",
      "Epoch 35/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.4760 - accuracy: 0.5563 - val_loss: 1.4068 - val_accuracy: 0.5913\n",
      "\n",
      "Fold 3\n",
      "(46309, 28, 44, 1)\n",
      "(11577, 28, 44, 1)\n",
      "(46309, 30)\n",
      "(11577, 30)\n",
      "Model: \"sequential_2\"\n",
      "________________________________________________________________________________\n",
      " Layer (type)                       Output Shape                    Param #     \n",
      "================================================================================\n",
      " conv2d_4 (Conv2D)                  (None, 26, 42, 32)              320         \n",
      "                                                                                \n",
      " max_pooling2d_4 (MaxPooling2D)     (None, 13, 21, 32)              0           \n",
      "                                                                                \n",
      " dropout_4 (Dropout)                (None, 13, 21, 32)              0           \n",
      "                                                                                \n",
      " conv2d_5 (Conv2D)                  (None, 11, 19, 32)              9248        \n",
      "                                                                                \n",
      " max_pooling2d_5 (MaxPooling2D)     (None, 5, 9, 32)                0           \n",
      "                                                                                \n",
      " dropout_5 (Dropout)                (None, 5, 9, 32)                0           \n",
      "                                                                                \n",
      " flatten_2 (Flatten)                (None, 1440)                    0           \n",
      "                                                                                \n",
      " dense_2 (Dense)                    (None, 30)                      43230       \n",
      "                                                                                \n",
      "================================================================================\n",
      "Total params: 52,798\n",
      "Trainable params: 52,798\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n",
      "Epoch 1/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 2.9679 - accuracy: 0.1660 - val_loss: 2.4396 - val_accuracy: 0.3276\n",
      "Epoch 2/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 2.3484 - accuracy: 0.3221 - val_loss: 2.0573 - val_accuracy: 0.4204\n",
      "Epoch 3/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 2.1063 - accuracy: 0.3861 - val_loss: 1.9045 - val_accuracy: 0.4519\n",
      "Epoch 4/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.9712 - accuracy: 0.4245 - val_loss: 1.8022 - val_accuracy: 0.4896\n",
      "Epoch 5/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.8896 - accuracy: 0.4463 - val_loss: 1.7445 - val_accuracy: 0.4981\n",
      "Epoch 6/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.8312 - accuracy: 0.4611 - val_loss: 1.7037 - val_accuracy: 0.5155\n",
      "Epoch 7/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.7897 - accuracy: 0.4728 - val_loss: 1.6514 - val_accuracy: 0.5278\n",
      "Epoch 8/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.7559 - accuracy: 0.4803 - val_loss: 1.6415 - val_accuracy: 0.5346\n",
      "Epoch 9/35\n",
      "1448/1448 [==============================] - 33s 23ms/step - loss: 1.7219 - accuracy: 0.4895 - val_loss: 1.6186 - val_accuracy: 0.5367\n",
      "Epoch 10/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6909 - accuracy: 0.4985 - val_loss: 1.5955 - val_accuracy: 0.5465\n",
      "Epoch 11/35\n",
      "1448/1448 [==============================] - 34s 23ms/step - loss: 1.6643 - accuracy: 0.5075 - val_loss: 1.5728 - val_accuracy: 0.5451\n",
      "Epoch 12/35\n",
      "1448/1448 [==============================] - 34s 23ms/step - loss: 1.6490 - accuracy: 0.5106 - val_loss: 1.5544 - val_accuracy: 0.5495\n",
      "Epoch 13/35\n",
      "1448/1448 [==============================] - 34s 23ms/step - loss: 1.6356 - accuracy: 0.5143 - val_loss: 1.5237 - val_accuracy: 0.5621\n",
      "Epoch 14/35\n",
      "1448/1448 [==============================] - 34s 23ms/step - loss: 1.6001 - accuracy: 0.5238 - val_loss: 1.5081 - val_accuracy: 0.5637\n",
      "Epoch 15/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5916 - accuracy: 0.5259 - val_loss: 1.5087 - val_accuracy: 0.5623\n",
      "Epoch 16/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.5674 - accuracy: 0.5293 - val_loss: 1.4914 - val_accuracy: 0.5704\n",
      "Epoch 17/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.5575 - accuracy: 0.5353 - val_loss: 1.4756 - val_accuracy: 0.5728\n",
      "Epoch 18/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5477 - accuracy: 0.5375 - val_loss: 1.4678 - val_accuracy: 0.5744\n",
      "Epoch 19/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.5365 - accuracy: 0.5391 - val_loss: 1.4753 - val_accuracy: 0.5709\n",
      "Epoch 20/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5290 - accuracy: 0.5425 - val_loss: 1.4641 - val_accuracy: 0.5745\n",
      "Epoch 21/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5207 - accuracy: 0.5438 - val_loss: 1.4431 - val_accuracy: 0.5780\n",
      "Epoch 22/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5064 - accuracy: 0.5470 - val_loss: 1.4265 - val_accuracy: 0.5823\n",
      "Epoch 23/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.4988 - accuracy: 0.5498 - val_loss: 1.4325 - val_accuracy: 0.5837\n",
      "Epoch 24/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.4950 - accuracy: 0.5510 - val_loss: 1.4285 - val_accuracy: 0.5868\n",
      "Epoch 25/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.4898 - accuracy: 0.5523 - val_loss: 1.4167 - val_accuracy: 0.5862\n",
      "Epoch 26/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.4837 - accuracy: 0.5540 - val_loss: 1.4241 - val_accuracy: 0.5853\n",
      "Epoch 27/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.4824 - accuracy: 0.5543 - val_loss: 1.4125 - val_accuracy: 0.5839\n",
      "Epoch 28/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.4709 - accuracy: 0.5579 - val_loss: 1.4135 - val_accuracy: 0.5869\n",
      "Epoch 29/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.4729 - accuracy: 0.5585 - val_loss: 1.3923 - val_accuracy: 0.5917\n",
      "Epoch 30/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.4668 - accuracy: 0.5548 - val_loss: 1.4058 - val_accuracy: 0.5903\n",
      "Epoch 31/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.4601 - accuracy: 0.5624 - val_loss: 1.3945 - val_accuracy: 0.5916\n",
      "Epoch 32/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.4577 - accuracy: 0.5608 - val_loss: 1.4206 - val_accuracy: 0.5838\n",
      "Epoch 33/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.4517 - accuracy: 0.5624 - val_loss: 1.4061 - val_accuracy: 0.5898\n",
      "Epoch 34/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.4544 - accuracy: 0.5604 - val_loss: 1.3773 - val_accuracy: 0.5983\n",
      "Epoch 35/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.4416 - accuracy: 0.5639 - val_loss: 1.3885 - val_accuracy: 0.5918\n",
      "\n",
      "Fold 4\n",
      "(46309, 28, 44, 1)\n",
      "(11577, 28, 44, 1)\n",
      "(46309, 30)\n",
      "(11577, 30)\n",
      "Model: \"sequential_3\"\n",
      "________________________________________________________________________________\n",
      " Layer (type)                       Output Shape                    Param #     \n",
      "================================================================================\n",
      " conv2d_6 (Conv2D)                  (None, 26, 42, 32)              320         \n",
      "                                                                                \n",
      " max_pooling2d_6 (MaxPooling2D)     (None, 13, 21, 32)              0           \n",
      "                                                                                \n",
      " dropout_6 (Dropout)                (None, 13, 21, 32)              0           \n",
      "                                                                                \n",
      " conv2d_7 (Conv2D)                  (None, 11, 19, 32)              9248        \n",
      "                                                                                \n",
      " max_pooling2d_7 (MaxPooling2D)     (None, 5, 9, 32)                0           \n",
      "                                                                                \n",
      " dropout_7 (Dropout)                (None, 5, 9, 32)                0           \n",
      "                                                                                \n",
      " flatten_3 (Flatten)                (None, 1440)                    0           \n",
      "                                                                                \n",
      " dense_3 (Dense)                    (None, 30)                      43230       \n",
      "                                                                                \n",
      "================================================================================\n",
      "Total params: 52,798\n",
      "Trainable params: 52,798\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n",
      "Epoch 1/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 2.9651 - accuracy: 0.1622 - val_loss: 2.4110 - val_accuracy: 0.3213\n",
      "Epoch 2/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 2.3666 - accuracy: 0.3199 - val_loss: 2.0985 - val_accuracy: 0.4146\n",
      "Epoch 3/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 2.1616 - accuracy: 0.3763 - val_loss: 1.9669 - val_accuracy: 0.4448\n",
      "Epoch 4/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 2.0633 - accuracy: 0.4009 - val_loss: 1.8689 - val_accuracy: 0.4684\n",
      "Epoch 5/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 2.0000 - accuracy: 0.4171 - val_loss: 1.8435 - val_accuracy: 0.4785\n",
      "Epoch 6/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.9529 - accuracy: 0.4305 - val_loss: 1.7855 - val_accuracy: 0.5002\n",
      "Epoch 7/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.9105 - accuracy: 0.4422 - val_loss: 1.7440 - val_accuracy: 0.5086\n",
      "Epoch 8/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.8831 - accuracy: 0.4490 - val_loss: 1.7427 - val_accuracy: 0.5076\n",
      "Epoch 9/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.8571 - accuracy: 0.4537 - val_loss: 1.6879 - val_accuracy: 0.5151\n",
      "Epoch 10/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.8310 - accuracy: 0.4605 - val_loss: 1.6620 - val_accuracy: 0.5220\n",
      "Epoch 11/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.8117 - accuracy: 0.4632 - val_loss: 1.6545 - val_accuracy: 0.5243\n",
      "Epoch 12/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.7860 - accuracy: 0.4715 - val_loss: 1.6470 - val_accuracy: 0.5255\n",
      "Epoch 13/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.7636 - accuracy: 0.4779 - val_loss: 1.6304 - val_accuracy: 0.5339\n",
      "Epoch 14/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.7494 - accuracy: 0.4832 - val_loss: 1.6233 - val_accuracy: 0.5389\n",
      "Epoch 15/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.7231 - accuracy: 0.4857 - val_loss: 1.5979 - val_accuracy: 0.5425\n",
      "Epoch 16/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.7043 - accuracy: 0.4960 - val_loss: 1.5847 - val_accuracy: 0.5428\n",
      "Epoch 17/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1448/1448 [==============================] - 33s 23ms/step - loss: 1.6752 - accuracy: 0.5034 - val_loss: 1.5563 - val_accuracy: 0.5503\n",
      "Epoch 18/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6622 - accuracy: 0.5056 - val_loss: 1.5588 - val_accuracy: 0.5492\n",
      "Epoch 19/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.6522 - accuracy: 0.5096 - val_loss: 1.5389 - val_accuracy: 0.5575\n",
      "Epoch 20/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.6436 - accuracy: 0.5106 - val_loss: 1.5267 - val_accuracy: 0.5596\n",
      "Epoch 21/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6276 - accuracy: 0.5155 - val_loss: 1.5142 - val_accuracy: 0.5671\n",
      "Epoch 22/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6140 - accuracy: 0.5177 - val_loss: 1.5090 - val_accuracy: 0.5625\n",
      "Epoch 23/35\n",
      "1448/1448 [==============================] - 37s 25ms/step - loss: 1.6082 - accuracy: 0.5202 - val_loss: 1.5124 - val_accuracy: 0.5659\n",
      "Epoch 24/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.5951 - accuracy: 0.5218 - val_loss: 1.5027 - val_accuracy: 0.5685\n",
      "Epoch 25/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5900 - accuracy: 0.5245 - val_loss: 1.4934 - val_accuracy: 0.5669\n",
      "Epoch 26/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.5839 - accuracy: 0.5246 - val_loss: 1.5038 - val_accuracy: 0.5586\n",
      "Epoch 27/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5812 - accuracy: 0.5280 - val_loss: 1.4919 - val_accuracy: 0.5707\n",
      "Epoch 28/35\n",
      "1448/1448 [==============================] - 33s 22ms/step - loss: 1.5749 - accuracy: 0.5321 - val_loss: 1.4915 - val_accuracy: 0.5721\n",
      "Epoch 29/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.5786 - accuracy: 0.5264 - val_loss: 1.4782 - val_accuracy: 0.5731\n",
      "Epoch 30/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5616 - accuracy: 0.5319 - val_loss: 1.4658 - val_accuracy: 0.5757\n",
      "Epoch 31/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.5582 - accuracy: 0.5352 - val_loss: 1.4648 - val_accuracy: 0.5756\n",
      "Epoch 32/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.5454 - accuracy: 0.5366 - val_loss: 1.4615 - val_accuracy: 0.5804\n",
      "Epoch 33/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5443 - accuracy: 0.5368 - val_loss: 1.4512 - val_accuracy: 0.5802\n",
      "Epoch 34/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.5439 - accuracy: 0.5381 - val_loss: 1.4917 - val_accuracy: 0.5711\n",
      "Epoch 35/35\n",
      "1448/1448 [==============================] - 38s 26ms/step - loss: 1.5316 - accuracy: 0.5419 - val_loss: 1.4443 - val_accuracy: 0.5869\n",
      "\n",
      "Fold 5\n",
      "(46309, 28, 44, 1)\n",
      "(11577, 28, 44, 1)\n",
      "(46309, 30)\n",
      "(11577, 30)\n",
      "Model: \"sequential_4\"\n",
      "________________________________________________________________________________\n",
      " Layer (type)                       Output Shape                    Param #     \n",
      "================================================================================\n",
      " conv2d_8 (Conv2D)                  (None, 26, 42, 32)              320         \n",
      "                                                                                \n",
      " max_pooling2d_8 (MaxPooling2D)     (None, 13, 21, 32)              0           \n",
      "                                                                                \n",
      " dropout_8 (Dropout)                (None, 13, 21, 32)              0           \n",
      "                                                                                \n",
      " conv2d_9 (Conv2D)                  (None, 11, 19, 32)              9248        \n",
      "                                                                                \n",
      " max_pooling2d_9 (MaxPooling2D)     (None, 5, 9, 32)                0           \n",
      "                                                                                \n",
      " dropout_9 (Dropout)                (None, 5, 9, 32)                0           \n",
      "                                                                                \n",
      " flatten_4 (Flatten)                (None, 1440)                    0           \n",
      "                                                                                \n",
      " dense_4 (Dense)                    (None, 30)                      43230       \n",
      "                                                                                \n",
      "================================================================================\n",
      "Total params: 52,798\n",
      "Trainable params: 52,798\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n",
      "Epoch 1/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 2.9506 - accuracy: 0.1660 - val_loss: 2.4677 - val_accuracy: 0.3150\n",
      "Epoch 2/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 2.3720 - accuracy: 0.3122 - val_loss: 2.0796 - val_accuracy: 0.4194\n",
      "Epoch 3/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 2.1613 - accuracy: 0.3744 - val_loss: 1.9129 - val_accuracy: 0.4588\n",
      "Epoch 4/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 2.0470 - accuracy: 0.4028 - val_loss: 1.8510 - val_accuracy: 0.4772\n",
      "Epoch 5/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.9784 - accuracy: 0.4230 - val_loss: 1.7857 - val_accuracy: 0.4911\n",
      "Epoch 6/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.9176 - accuracy: 0.4373 - val_loss: 1.7436 - val_accuracy: 0.5101\n",
      "Epoch 7/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.8704 - accuracy: 0.4490 - val_loss: 1.6791 - val_accuracy: 0.5152\n",
      "Epoch 8/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.8280 - accuracy: 0.4619 - val_loss: 1.6471 - val_accuracy: 0.5291\n",
      "Epoch 9/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.7984 - accuracy: 0.4669 - val_loss: 1.6627 - val_accuracy: 0.5269\n",
      "Epoch 10/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.7673 - accuracy: 0.4761 - val_loss: 1.6059 - val_accuracy: 0.5371\n",
      "Epoch 11/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.7516 - accuracy: 0.4817 - val_loss: 1.5994 - val_accuracy: 0.5414\n",
      "Epoch 12/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.7298 - accuracy: 0.4840 - val_loss: 1.5787 - val_accuracy: 0.5419\n",
      "Epoch 13/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.7118 - accuracy: 0.4934 - val_loss: 1.5506 - val_accuracy: 0.5528\n",
      "Epoch 14/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6827 - accuracy: 0.5014 - val_loss: 1.5520 - val_accuracy: 0.5509\n",
      "Epoch 15/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6677 - accuracy: 0.5018 - val_loss: 1.5469 - val_accuracy: 0.5586\n",
      "Epoch 16/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.6478 - accuracy: 0.5086 - val_loss: 1.4997 - val_accuracy: 0.5636\n",
      "Epoch 17/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.6280 - accuracy: 0.5174 - val_loss: 1.4901 - val_accuracy: 0.5692\n",
      "Epoch 18/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6164 - accuracy: 0.5163 - val_loss: 1.4901 - val_accuracy: 0.5661\n",
      "Epoch 19/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.6011 - accuracy: 0.5237 - val_loss: 1.4598 - val_accuracy: 0.5733\n",
      "Epoch 20/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.5847 - accuracy: 0.5267 - val_loss: 1.4768 - val_accuracy: 0.5696\n",
      "Epoch 21/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5809 - accuracy: 0.5268 - val_loss: 1.4467 - val_accuracy: 0.5736\n",
      "Epoch 22/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5670 - accuracy: 0.5315 - val_loss: 1.4494 - val_accuracy: 0.5699\n",
      "Epoch 23/35\n",
      "1448/1448 [==============================] - 35s 25ms/step - loss: 1.5650 - accuracy: 0.5306 - val_loss: 1.4530 - val_accuracy: 0.5777\n",
      "Epoch 24/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5474 - accuracy: 0.5359 - val_loss: 1.4514 - val_accuracy: 0.5768\n",
      "Epoch 25/35\n",
      "1448/1448 [==============================] - 36s 25ms/step - loss: 1.5426 - accuracy: 0.5363 - val_loss: 1.4317 - val_accuracy: 0.5803\n",
      "Epoch 26/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5352 - accuracy: 0.5372 - val_loss: 1.4282 - val_accuracy: 0.5826\n",
      "Epoch 27/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.5254 - accuracy: 0.5430 - val_loss: 1.4311 - val_accuracy: 0.5789\n",
      "Epoch 28/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5287 - accuracy: 0.5383 - val_loss: 1.4198 - val_accuracy: 0.5838\n",
      "Epoch 29/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5270 - accuracy: 0.5412 - val_loss: 1.4118 - val_accuracy: 0.5862\n",
      "Epoch 30/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5194 - accuracy: 0.5441 - val_loss: 1.4203 - val_accuracy: 0.5814\n",
      "Epoch 31/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5188 - accuracy: 0.5397 - val_loss: 1.4139 - val_accuracy: 0.5847\n",
      "Epoch 32/35\n",
      "1448/1448 [==============================] - 34s 24ms/step - loss: 1.5044 - accuracy: 0.5462 - val_loss: 1.3930 - val_accuracy: 0.5882\n",
      "Epoch 33/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5062 - accuracy: 0.5474 - val_loss: 1.4326 - val_accuracy: 0.5813\n",
      "Epoch 34/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.5027 - accuracy: 0.5484 - val_loss: 1.3984 - val_accuracy: 0.5889\n",
      "Epoch 35/35\n",
      "1448/1448 [==============================] - 35s 24ms/step - loss: 1.4919 - accuracy: 0.5483 - val_loss: 1.4003 - val_accuracy: 0.5881\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
    "print(X_test.shape)\n",
    "nfold = 5\n",
    "kf = KFold(n_splits=nfold, shuffle=True, random_state=2020)\n",
    "prediction1 = np.zeros((len(X_test),30 ))\n",
    "i = 0\n",
    "for train_index, valid_index in kf.split(features, labels):\n",
    "    print(\"\\nFold {}\".format(i + 1))\n",
    "    train_x, train_y = features[train_index],labels[train_index]\n",
    "    val_x, val_y = features[valid_index],labels[valid_index]\n",
    "    train_x = train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)\n",
    "    val_x = val_x.reshape(val_x.shape[0],val_x.shape[1],val_x.shape[2],1)\n",
    "    print(train_x.shape)\n",
    "    print(val_x.shape)\n",
    "    train_y = to_categorical(train_y,30)\n",
    "    val_y = to_categorical(val_y,30)\n",
    "    print(train_y.shape)\n",
    "    print(val_y.shape)\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, (3, 3), activation='relu',input_shape = train_x.shape[1:]))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25)) \n",
    "    model.add(Convolution2D(32, (3, 3),  activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(30, activation='softmax'))\n",
    "    model.compile(optimizer='Adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    model.summary(line_length=80)\n",
    "    history = model.fit(train_x, train_y, epochs=35, batch_size=32, validation_data=(val_x, val_y))\n",
    "    y1 = model.predict(X_test)\n",
    "    prediction1 += ((y1)) / nfold\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53bb467b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6835\n",
      "['yes', 'on', 'cat', 'stop', 'no', 'off', 'four', 'on', 'no', 'happy']\n"
     ]
    }
   ],
   "source": [
    "y_pred=[list(x).index(max(x)) for x in prediction1]\n",
    "sub = pd.read_csv('D:\\\\下载\\\\submission.csv')\n",
    "cnt = 0\n",
    "result = [0 for i in range(6835)]\n",
    "for i in range(6835):\n",
    "    ss = sub.iloc[i]['file_name']\n",
    "    for j in range(6835):\n",
    "        if fl[j] == ss:\n",
    "            result[i] = y_pred[j]\n",
    "            cnt = cnt+1\n",
    "print(cnt)\n",
    "result1 = []\n",
    "for i in range(len(result)):\n",
    "    result1.append(filename_list[result[i]])\n",
    "print(result1[0:10])\n",
    "df = pd.DataFrame({'file_name':sub['file_name'],'label':result1})\n",
    "now = time.strftime(\"%Y%m%d_%H%M%S\",time.localtime(time.time())) \n",
    "fname=\"D:\\\\下载\\\\submit_\"+now+r\".csv\"    \n",
    "df.to_csv(fname, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c77b189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44227b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f2769e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32842d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2141ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
